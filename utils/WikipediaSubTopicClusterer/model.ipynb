{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "937846cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import html\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6f023978",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/india'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d89f9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ff56b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c8fe2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_content = soup.select_one('div#bodyContent')\n",
    "if main_content:\n",
    "    infobox = main_content.select_one(\"table.infobox.vcard.plainlist\")\n",
    "    citation_box1 = main_content.select_one('.box-More_citations_needed.plainlinks.metadata.ambox.ambox-content.ambox-Refimprove')\n",
    "    if citation_box1:\n",
    "        citation_box1.decompose()\n",
    "    if infobox:\n",
    "        infobox.decompose()\n",
    "    if main_content.find_all('figure'):\n",
    "        for tag in soup.find_all('figure'):\n",
    "            tag.decompose()\n",
    "    see_also_header = main_content.select_one(\"h2#See_also\")\n",
    "    notes_header = main_content.select_one(\"h2#Notes\")\n",
    "    references_header = main_content.select_one(\"h2#References\")\n",
    "    if see_also_header:\n",
    "        parent_tag = see_also_header.parent\n",
    "    elif notes_header:\n",
    "        parent_tag = notes_header.parent\n",
    "    elif references_header:\n",
    "        parent_tag = references_header.parent\n",
    "    if parent_tag:\n",
    "        for sibling in list(parent_tag.find_next_siblings()):\n",
    "            sibling.decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "426faeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wikipedia_text(text: str) -> str:\n",
    "    # Decode HTML entities (e.g., &nbsp;, &#x27;)\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # 1. Remove citation brackets like [51], [edit], etc.\n",
    "    text = re.sub(r\"\\[\\d+\\]\", \"\", text)\n",
    "    text = re.sub(r\"\\[edit\\]\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # # 2. Remove mathematical/LaTeX-like expressions or weird equations\n",
    "    text = re.sub(r\"\\{\\\\displaystyle.*?\\}\", \"\", text, flags=re.DOTALL)\n",
    "    text = re.sub(r\"[{}^_\\\\]+\", \"\", text)\n",
    "\n",
    "    # 3. Remove sections starting with “See also”, “References”, “Notes”, “External links”\n",
    "    section_markers = [\"See also\", \"References\", \"Notes\", \"External links\"]\n",
    "    \n",
    "    for marker in section_markers:\n",
    "        text = text.replace(marker,\"\")\n",
    "    text = re.sub(r\"\\[\\s*edit\\s*\\]\", \"\", text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    # 4. Remove “Retrieved from...” and category listings\n",
    "    text = re.split(r\"Retrieved from .*\", text)[0]\n",
    "    text = re.sub(r\"Categories?:.*\", \"\", text, flags=re.DOTALL)\n",
    "\n",
    "    # 5. Remove any remaining edit links or source links\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)  # Generic cleanup for leftover square brackets\n",
    "\n",
    "    # 6. Normalize unicode quotes and dashes\n",
    "    text = text.replace(\"’\", \"'\").replace(\"“\", '\"').replace(\"”\", '\"').replace(\"–\", \"-\")\n",
    "\n",
    "    # 7. Remove extra whitespace, multiple line breaks, etc.\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\"[ \\t]{2,}\", \" \", text)\n",
    "\n",
    "    # Remove newlines and collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Remove boilerplate phrases (you can add more if needed)\n",
    "    patterns_to_remove = [\n",
    "        r\"From Wikipedia, the free encyclopedia\",\n",
    "        r\"This article.*?verification\\s*\\.\",  # matches citation warnings\n",
    "        r\"Please help.*?reliable sources\\s*\\.\",\n",
    "        r\"Unsourced material.*?removed\\s*\\.\",\n",
    "        r\"Find sources:.*?\\)\",  # matches source listings like JSTOR etc.\n",
    "    ]\n",
    "    for pattern in patterns_to_remove:\n",
    "        text = re.sub(pattern, \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove numbered citations like [1], [2], etc.\n",
    "    text = re.sub(r\"\\[\\s*\\d+\\s*\\]\", \"\", text)\n",
    "\n",
    "    # Strip leading/trailing whitespace\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e23954ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_wikipedia_text(main_content.get_text(separator=\"\\n\", strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "20cff17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    # Replace common abbreviations temporarily to avoid splitting there\n",
    "    abbreviations = {\"e.g.\": \"eg_placeholder\", \"i.e.\": \"ie_placeholder\"}\n",
    "    \n",
    "    for abbr, placeholder in abbreviations.items():\n",
    "        text = text.replace(abbr, placeholder)\n",
    "    \n",
    "    # Now split by period followed by space/newline\n",
    "    sentences = re.split(r\"\\.\\s+\", text)\n",
    "    \n",
    "    # Restore the abbreviations\n",
    "    sentences = [s.replace(\"eg_placeholder\", \"e.g.\").replace(\"ie_placeholder\", \"i.e.\") for s in sentences]\n",
    "    \n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "sentences = split_sentences(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b7180d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_cluster_sentences(sentences, distance_range=(0.5, 3.0, 20)):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(sentences)\n",
    "\n",
    "    Z = linkage(embeddings, method='ward')\n",
    "\n",
    "    # Find optimal `t` based on silhouette score\n",
    "    best_score = -1\n",
    "    best_t = None\n",
    "    best_labels = None\n",
    "\n",
    "    max_clusters = 50  # set maximum clusters allowed\n",
    "\n",
    "    for t in np.linspace(*distance_range):\n",
    "        labels = fcluster(Z, t, criterion='distance')\n",
    "        n_clusters = len(set(labels))\n",
    "        n_samples = len(sentences)\n",
    "\n",
    "        # Skip if less than 2 clusters or more than max_clusters or invalid silhouette condition\n",
    "        if n_clusters < 2 or n_clusters > max_clusters or n_clusters >= n_samples:\n",
    "            continue\n",
    "\n",
    "        score = silhouette_score(embeddings, labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_t = t\n",
    "            best_labels = labels\n",
    "\n",
    "    print(f\"Best t = {best_t:.2f} with silhouette score = {best_score:.4f}\")\n",
    "\n",
    "    # Group sentences and embeddings by cluster label\n",
    "    clusters = {}\n",
    "    for idx, (label, sent) in enumerate(zip(best_labels, sentences)):\n",
    "        clusters.setdefault(label, []).append((sent, embeddings[idx]))\n",
    "\n",
    "    named_clusters = {}\n",
    "    for label, sentence_tuples in clusters.items():\n",
    "        sents, embs = zip(*sentence_tuples)\n",
    "\n",
    "        # Calculate centroid embedding for the cluster\n",
    "        centroid = np.mean(embs, axis=0, keepdims=True)\n",
    "\n",
    "        # Find the sentence closest to centroid (central sentence)\n",
    "        distances = cosine_distances(centroid, embs)[0]\n",
    "        central_idx = np.argmin(distances)\n",
    "        central_sentence = sents[central_idx]\n",
    "\n",
    "        # Extract top 3 TF-IDF keywords for the cluster sentences\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        X = vectorizer.fit_transform(sents)\n",
    "        feature_array = np.array(vectorizer.get_feature_names_out())\n",
    "        tfidf_scores = X.mean(axis=0).A1\n",
    "        if len(feature_array) >= 3:\n",
    "            top_keywords = feature_array[np.argsort(tfidf_scores)[-3:]][::-1]\n",
    "        else:\n",
    "            top_keywords = feature_array[np.argsort(tfidf_scores)][::-1]\n",
    "\n",
    "        keywords_str = \", \".join(top_keywords)\n",
    "\n",
    "         # Check if any of the top keywords are in the central sentence (case-insensitive)\n",
    "        central_sentence_lower = central_sentence.lower()\n",
    "        keywords_in_central = [kw for kw in top_keywords if kw.lower() in central_sentence_lower]\n",
    "        if keywords_in_central:\n",
    "            # If any keyword is found in the central sentence, use them\n",
    "            keywords_str = \", \".join(keywords_in_central)\n",
    "        else:\n",
    "            # Otherwise, use the top keywords\n",
    "            keywords_str = \", \".join(top_keywords)\n",
    "\n",
    "        cluster_title = f\"{keywords_str}\"\n",
    "\n",
    "        named_clusters[cluster_title] = sents\n",
    "\n",
    "    return named_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "81c24b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best t = 1.68 with silhouette score = 0.0543\n"
     ]
    }
   ],
   "source": [
    "clusters = hierarchical_cluster_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ad77e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_clusters_as_df(named_clusters):\n",
    "    rows = []\n",
    "    for cluster_title, sents in named_clusters.items():\n",
    "        for sent in sents:\n",
    "            rows.append({\"Key ideas\": cluster_title, \"Sentence\": sent})\n",
    "    return pd.DataFrame(rows)\n",
    "df = format_clusters_as_df(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6e05fe92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key ideas</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>india, indian</td>\n",
       "      <td>Coordinates : 21°N 78°E ﻿ / ﻿ 21°N 78°E ﻿ / 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>india, indian</td>\n",
       "      <td>Bounded by the Indian Ocean on the south, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>india, indian</td>\n",
       "      <td>In the Indian Ocean, India is near Sri Lanka a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>india, indian</td>\n",
       "      <td>The meaning of Hindustan has varied, referring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>india, indian</td>\n",
       "      <td>Geography Main article: Geography of India Ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>india, indian, cuisine</td>\n",
       "      <td>Dishes such as the pilaf ,  developed in the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>india, indian, cuisine</td>\n",
       "      <td>To the simple yogurt marinade of Persia, onion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>india, indian, cuisine</td>\n",
       "      <td>Rice was partially cooked and layered alternat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>india, indian, cuisine</td>\n",
       "      <td>In the food served in Indian restaurants world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>india, indian, cuisine</td>\n",
       "      <td>The popularity of tandoori chicken —cooked in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Key ideas                                           Sentence\n",
       "0             india, indian  Coordinates : 21°N 78°E ﻿ / ﻿ 21°N 78°E ﻿ / 21...\n",
       "1             india, indian  Bounded by the Indian Ocean on the south, the ...\n",
       "2             india, indian  In the Indian Ocean, India is near Sri Lanka a...\n",
       "3             india, indian  The meaning of Hindustan has varied, referring...\n",
       "4             india, indian  Geography Main article: Geography of India Ind...\n",
       "..                      ...                                                ...\n",
       "379  india, indian, cuisine  Dishes such as the pilaf ,  developed in the A...\n",
       "380  india, indian, cuisine  To the simple yogurt marinade of Persia, onion...\n",
       "381  india, indian, cuisine  Rice was partially cooked and layered alternat...\n",
       "382  india, indian, cuisine  In the food served in Indian restaurants world...\n",
       "383  india, indian, cuisine  The popularity of tandoori chicken —cooked in ...\n",
       "\n",
       "[384 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5402f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
